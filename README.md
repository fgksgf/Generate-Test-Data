# Spark 和B+-Tree

```
目标:对于HDFS上存储的数据生成B+-Tree索引并进一步利用B+-Tree索引
􏰀
- 建立索引
	– 输入:HDFS输入数据(JSON格式)，建立索引的域(例如a.b.c) 
	– 用Spark计算并在HDFS上生成文件对应输入的有序索引
􏰀
- 使用索引
	– 在Spark加载数据时，可以对索引的域给出过滤条件
	– 加载过程中利用索引完成过滤，仅把满足条件的数据放入RDD
􏰀
讨论:除了上述场景外，在Spark中还有什么方式可能使 用索引?或者不可能使用索引?为什么?
```



## 1. 测试用例的构建（JHX）

### 需求

+ 随机生成1MB，10MB，100MB，1000MB的json数据文件
+ 对每一个json，随机产生10个查询条件，以及在该条件下的预期结果

### 依赖

+ Gson 2.8.6

### 说明

+   随机json数据文件以文件大小命名，如“1MB.json”，内容如下所示：

```json
{[
 {
        "name": "jEFig",
        "sex": "female",
        "age": 26,
        "salary": 2400,
        "features": [0.8049025, 0.9714222, 0.7855754, 0.12631243, 0.48011535]
    }, {
        "name": "JXKDA",
        "sex": "male",
        "age": 38,
        "salary": 31200,
        "features": [0.53826284, 0.95286286, 0.6646409, 0.9182997, 0.8044558]
    }
]}
```

+   查询条件仅仅限于：`>，<，==，>=，<=` ，可以有双边，如 1 < field <= 3，以空格分隔
+   符合查询条件的预期结果保存为json格式，命名格式为“<文件大小>-<查询条件>.json”，例如 “1MB-age > 20.json”。

## 